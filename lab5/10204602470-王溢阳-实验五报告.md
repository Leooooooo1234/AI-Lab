# 当代人工智能实验5：多模态情感分类

| 姓名：王溢阳   | 学号：10204602470            | 学院：数据科学与工程学院 |
| -------------- | ---------------------------- | ------------------------ |
| 指导教师：李翔 | 上机实践时间：2023年12月28日 | 上机实践分数：           |

## 一. 实验要求

### 实验任务

- 给定配对的文本和图像，预测对应的情感标签
- 三分类任务：Positive，neutral， negative

### 实验数据集

- 匿名数据集（实验五数据.zip）
  - data文件夹：包括所有的训练文本和图片，每个文件按照唯一的guid命名
  - train.txt:数据的guid和对应的情感标签
  - test_withot_lable.txt:数据的guid和空的情感标签

### 实验要求

- 设计一个多模态融合模型
- 自行从训练集中划分验证集，调整超参数
- 预测测试集（test_without_lable.txt)上的情感标签

### 代码和报告要求

- 代码可执行，结果可复现
- 报告必须包含的四点：
  - 代码实现时遇到了哪些bug?如何解决的？
  - 你为什么会涉及这样的模型？你觉得你的模型有什么亮点？
  - 多模态融合模型在验证集上的结果
  - 消融实验结果。即分别只输入文本或图像数据，你的多模态融合模型在验证集会获得怎样的表现

### 额外要求

- 把自己的代码上传到github，将该github地址添加到报告中的第一页。要求有完整详细的readme。
  - 执行你代码所需要的环境。写在一个requirements.txt中
  - 你的代码文件结构
  - 执行你代码的完整流程
  - 你这篇代码参考哪些库实现的
  - 可参考https://github.com/RecklessRonan/GloGNN/blob/master/readme.md

### 提交要求

- 提交内容：代码+报告+测试集结果文件。
- 提交命名：学号+姓名+实验五。
- 测试集结果文件直接把对应标签位置的null换成positive或neutral或negative。
- 截止时间：2024年1月31号24点
- 提交到邮箱：程瑶<18697092891@163.com>

## 二. 实验环境

- 恒源云云主机实例

  ![image-20240130204451418](C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240130204451418.png)

  - 账号：ssh -p 55270 root@i-2.gpushare.com
  - 密码：bTvuS8GCuMTYXXVUVCEpgNH9pEbF2mvp

- 项目结构

  ```
  |- code
  	|- data_processor.py
  	|- main.py
  	|- model.py
  	|- roberta.py
  	|- train.py
  |- data
  	|- source
  	|- predicts.txt
  	|- text_without_lable.txt
  	|- train.txt
  |- 10204602470-王溢阳-实验五报告.md
  |- requirements.txt
  ```

- github项目地址：

## 三. 实验步骤

#### 3.1 数据预处理

> 代码见data_processor.py

- process_file:
  - 遍历数据文件，提取图片以及特征信息

- collate_fn:
  - 将一个batch的数据按照模型需要的格式进行打包和组织
  - 提取guid tag image和text
  - 将图像数据转化为tensor进行处理

- get_dataloader
  - 划分数据集为训练集和验证集
  - 将数据集转换为可以迭代的批量数据加载器

#### 3.2 模型构建

> 代码见model.py

- 文本部分
  - 采用XLM-RoBERTa作为基准模型
  - XLMRoBERTa是多语言预训练模型，RoBERTa通过对预训练任务的改进和参数的调优，大幅提升Bert的语义特征提取能力
  - XLM通过对文本嵌⼊方法的改进，使得多语言文本可以通过⼀种统⼀的方法输入模型。

- 图像部分
  - 采用ResNet-152作为基准模型
  - 残差链接的方法有效解决网络层数加深导致的输入特征消失以及学习偏差的问题
  - 将输入的图像转换为高级特征表示，从视觉角度获取图像中的情感暗示和重要特征

- 模型结构

  - TextModel
    - 使用预训练模型RoBERTa作为文本编码器，得到文本的特征表示

  - ImageModel
    - 使用预训练模型ResNet-152作为图像编码器

  - Classifier
    - 根据给定的模式选择不同的操作方式，经过线性层得到分类的输出

  - MultiModalModel
    - 使用前两个模型分别对文本和图像进行特征提取
    - 将图像和文本的特征进行拼接并获取注意力掩码
    - 注意力机制：使用ROBERTaLayer整合文本和图像特征
    - 通过分类器输出分类

  - 消融实验（text\image)
    - 只输入文字信息，不进行特征向量的拼接
    - 使用分类器的输入维度是融合模型的一半

#### 3.3 模型训练

> 代码见train.py

函数释义：

- criterion = CrossEntropyLoss():计算模型损失
- num_training_steps = len(train_dataloader) * args.epoches:计算训练步数
- optimizer_grouped_parameters:将模型参数氛围权重衰减以及不变的两组

## 四. 实验结果

> 预测结果见predicts.txt文件

- 融合模型：72%

  ![image-20240130215551049](C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240130215551049.png)

- 单文本模型：70%

  ![image-20240130215601981](C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240130215601981.png)

- 单图像模型：63%

  ![image-20240130215610670](C:\Users\86133\AppData\Roaming\Typora\typora-user-images\image-20240130215610670.png)

## 五. 总结

### 遇到的问题及解决方法

> huggingface无法连接的问题

- 报错：we couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like xlm-roberta-base is not the path to a directory containing a file named config.jason. Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/tranformers/installation#offline-mode'.

  - 解决：[Hugging Face 无法连接问题 OSError: We couldn‘t connect to ‘https://huggingface.co‘ to load this file 解决方案_huggingface运行连接失败-CSDN博客](https://blog.csdn.net/m0_46295727/article/details/133221439)


> 打开太多文件报错

- 报错：OSError:[Errno 24] Too many open files: '../data/source/5100.txt'

- 解决：图像文件打开后未及时关闭

  ```py
  img = Image.open(image_file)
  img.close()
  ```

